{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1a71388-f6b9-4964-8671-d680a4c2a165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x14e216c7570>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "torch.manual_seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "defb8bb2-8d0b-4dfc-b722-dc5e1fbe55b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_text = str(open('input.txt').read())\n",
    "chars = {}\n",
    "set_chars = set()\n",
    "for i in inp_text:\n",
    "    for j in str(i):\n",
    "        set_chars.add(j)\n",
    "for i, letter in enumerate(sorted(list(set_chars))):\n",
    "    chars[letter] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5854228-ad92-4bd2-a780-4973cb3ff501",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(chars)\n",
    "dims_num = 40\n",
    "context_len = 8\n",
    "batch_size = 4\n",
    "n_heads = 4\n",
    "n_layers = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f51a57a7-ca98-4b48-bdc4-bef0912b10b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(inp):\n",
    "    ans = []\n",
    "    for i in inp:\n",
    "        ans.append(chars[i])\n",
    "    return ans\n",
    "\n",
    "def decode(inp):\n",
    "    ans = \"\"\n",
    "    for i in inp:\n",
    "        ans+=str(keys_chars[i])\n",
    "    return ans\n",
    "\n",
    "def get_batch(data):\n",
    "    ixs = torch.randint(0, len(data)-context_len-1, (batch_size,))\n",
    "    x_batches = torch.stack([data[i:i+context_len] for i in ixs])\n",
    "    ys = torch.stack([data[i+1:i+context_len+1] for i in ixs])\n",
    "    x_batches, ys = x_batches.to(device), ys.to(device)\n",
    "    return x_batches, ys\n",
    "\n",
    "\n",
    "inp_text = torch.tensor(encode(inp_text), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39e2a681-229b-496b-80ab-e2e5fe1f0b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = int(0.9 * len(inp_text))\n",
    "train_data = inp_text[:n1]\n",
    "val_data = inp_text[n1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d05fc3b8-5bb4-4bec-9f2e-7c5a183e0a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56,  ..., 45,  8,  0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c362a302-181b-45d6-ae04-e38ae0230e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1115394])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e863f14c-6e30-4a48-9e0e-416d3ab9fd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "     def __init__(self):\n",
    "         super().__init__()\n",
    "         self.key = nn.Linear(dims_num, dims_num, bias=False)\n",
    "         self.query = nn.Linear(dims_num, dims_num, bias=False)\n",
    "         self.value = nn.Linear(dims_num, dims_num, bias=False)\n",
    "\n",
    "     def forward(self, x):\n",
    "         k = self.key(x) # B, T, D\n",
    "         q = self.query(x)\n",
    "         v = self.value(x)\n",
    "\n",
    "         x = q @ k.transpose(-2, -1) * k.shape[-1]**0.5\n",
    "         x = F.softmax(x, dim=-1)\n",
    "         out = x @ v\n",
    "         return out\n",
    "         \n",
    "\n",
    "class GPT(nn.Module):\n",
    "     def __init__(self):\n",
    "         super().__init__()\n",
    "         self.mean_emb = nn.Embedding(vocab_size, dims_num)\n",
    "         self.pos_emb = nn.Embedding(context_len, dims_num)\n",
    "         self.ll = nn.Linear(dims_num, vocab_size)\n",
    "\n",
    "     def forward(self, x, y):\n",
    "         B, T = x.shape\n",
    "         logits = self.mean_emb(x)\n",
    "         logits += self.pos_emb(torch.arange(T, device=device))\n",
    "         logits = self.ll(logits)\n",
    "         print(logits.shape)\n",
    "         logits = logits.view(B * T, -1)\n",
    "         y = y.view(B*T)\n",
    "         loss = F.cross_entropy(logits, y)\n",
    "         return logits, loss\n",
    "\n",
    "     def generate(self, inp, max_tokens):\n",
    "         return self(inp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9323ef2-f8a2-4195-9ddb-9ddabea50e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 65])\n"
     ]
    }
   ],
   "source": [
    "m = GPT()\n",
    "m = m.to(device)\n",
    "xs, ys = get_batch(train_data)\n",
    "logits, loss = m(xs, ys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "eccbd075-146b-474b-86eb-530e8d1014df",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(m.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ecc32b6b-a156-4a92-9389-665cfe528961",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10000):\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    xs, ys = get_batch(train_data)\n",
    "    logits, loss = m(xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e9ee70f0-7d00-4f32-9cf1-cb40763d45ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.4121, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a99402-7399-4be2-b608-4ff62d335785",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
