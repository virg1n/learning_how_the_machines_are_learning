Before starting lesson 3 i tried to create my own architecture of model that can take previous letters as an input. 
This was unsuccessful because of time to train: its was so long
BTW, here are results:
- egdjcwbviipe
- oyjlfikrxhqw
- axiwptjkulfu

It was 2 layers model with:
- 27*27
- 27
neuron layers
